{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, time\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import sys\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "# import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import rawpy\n",
    "%matplotlib inline\n",
    "\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    deviceTag = torch.device('cuda')\n",
    "else:\n",
    "    deviceTag = torch.device('cpu')\n",
    "print(deviceTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out\n",
    "\n",
    "def process_img(input_raw_img, model, ratio):\n",
    "    ## Process image(s) using the given model\n",
    "    # input_raw_img: numpy array, dimension: (Batch,Height,Width,Channel)\n",
    "    # ratio: numpy array, dimension: (Batch,)\n",
    "    model.eval();\n",
    "    model.to(deviceTag)\n",
    "    ratio = ratio.reshape(ratio.shape[0],1,1,1)\n",
    "    input_raw_img = np.transpose(input_raw_img, [0,3,1,2]).astype('float32')*ratio\n",
    "    input_tensor = torch.from_numpy(input_raw_img.copy()).float().to(deviceTag)\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)\n",
    "    output_img = output_tensor.cpu().numpy()\n",
    "    output_img = np.transpose(output_img, [0,2,3,1])\n",
    "    \n",
    "    return output_img\n",
    "\n",
    "def ssim_numpy(img1, img2):\n",
    "    img1, img2 = torch.tensor(np.transpose(img1,(2,0,1))).unsqueeze(0), torch.tensor(np.transpose(img2,(2,0,1))).unsqueeze(0)\n",
    "    ssim_calc = ssim(img1,img2, data_range=1, size_average=True)\n",
    "    msssim_calc = ms_ssim(img1,img2, data_range=1, size_average=True)\n",
    "    return ssim_calc.numpy(), msssim_calc.numpy()\n",
    "    \n",
    "def validate(model, input_list, gt_list, block_size = None, batch_size = 8, save_img_dir = None):\n",
    "    assert len(input_list) == len(gt_list)\n",
    "    \n",
    "    model.eval();\n",
    "    PSNR_list = []\n",
    "    SSIM_list = []\n",
    "    MSSSIM_list = []\n",
    "    \n",
    "    for i in range(len(input_list)//batch_size):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        input_raw_img_batch = []\n",
    "        gt_img_batch = []\n",
    "        ratio_batch = []\n",
    "        for b in range(batch_size):\n",
    "            if i*batch_size+b < len(input_list):\n",
    "                in_path = input_list[i*batch_size+b]\n",
    "                gt_path = gt_list[i*batch_size+b]\n",
    "            else:\n",
    "                break\n",
    "            in_fn = os.path.basename(in_path)\n",
    "            gt_fn = os.path.basename(gt_path)\n",
    "            in_exposure = float(in_fn[9:-5])\n",
    "            gt_exposure = float(gt_fn[9:-5])\n",
    "            ratio = min(gt_exposure / in_exposure, 300)\n",
    "        \n",
    "            raw = rawpy.imread(in_path)\n",
    "            input_raw_img = pack_raw(raw)\n",
    "            \n",
    "            gt_raw = rawpy.imread(gt_path)\n",
    "            gt_img = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            gt_img = np.float32(gt_img / 65535.0)\n",
    "            \n",
    "            if block_size is not None:\n",
    "                i_cut, j_cut = np.random.randint(0,input_raw_img.shape[0]-block_size), np.random.randint(0,input_raw_img.shape[1]-block_size)\n",
    "                gt_img = gt_img[i_cut*2:i_cut*2+block_size*2, j_cut*2:j_cut*2+block_size*2, :]\n",
    "                input_raw_img = input_raw_img[i_cut:i_cut+block_size, j_cut:j_cut+block_size, :]\n",
    "            \n",
    "            ratio_batch.append(ratio)\n",
    "            input_raw_img_batch.append(input_raw_img)\n",
    "            gt_img_batch.append(gt_img)\n",
    "        \n",
    "        input_raw_img_batch = np.array(input_raw_img_batch)\n",
    "        ratio_batch = np.array(ratio_batch)\n",
    "        gt_img_batch = np.array(gt_img_batch)\n",
    "        \n",
    "        output_img_batch = process_img(input_raw_img_batch, model, ratio_batch)\n",
    "        if save_img_dir is not None:\n",
    "            plt.imsave(save_img_dir+'{}_gt.png'.format(i),gt_img_batch[0,:,:,:])\n",
    "            plt.imsave(save_img_dir+'{}_out.png'.format(i),output_img_batch[0,:,:,:])\n",
    "        MSE = np.mean((output_img_batch.reshape(output_img_batch.shape[0],-1) - gt_img_batch.reshape(gt_img_batch.shape[0],-1))**2, axis = 1)\n",
    "        PSNR_batch = 10*np.log10(1/MSE)\n",
    "        PSNR_list.append(list(PSNR_batch))\n",
    "        ssim_calc, msssim_calc = ssim_numpy(gt_img_batch[0,:,:,:], output_img_batch[0,:,:,:])\n",
    "        SSIM_list.append(ssim_calc)\n",
    "        MSSSIM_list.append(msssim_calc)\n",
    "    \n",
    "    Val_PSNR = np.mean(PSNR_list)\n",
    "    Val_SSIM = np.mean(SSIM_list)\n",
    "    Val_MSSSIM = np.mean(MSSSIM_list)\n",
    "    return Val_PSNR, Val_SSIM, Val_MSSSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRIDNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_lrelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_lrelu, self).__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_ch,out_ch,3, padding = 1),nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.conv1 = conv_lrelu(in_ch,out_ch)\n",
    "        self.conv2 = conv_lrelu(out_ch,out_ch)\n",
    "        self.down =  nn.MaxPool2d((2,2))\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.down(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up, self).__init__()       \n",
    "        self.up =  nn.UpsamplingBilinear2d(scale_factor = 2)\n",
    "        self.conv1 = conv_lrelu(in_ch,out_ch) \n",
    "        self.conv2 = conv_lrelu(out_ch,out_ch) \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        if x1.shape != x2.shape:\n",
    "            x1 = transforms.functional.resize(x1, x2.shape[2:])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch = 4, CH_PER_SCALE = [32,64,128,256,512], out_ch = 12):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = conv_lrelu(in_ch, CH_PER_SCALE[0])\n",
    "        self.inc2 = conv_lrelu(CH_PER_SCALE[0], CH_PER_SCALE[0])\n",
    "        self.down1 = down(CH_PER_SCALE[0], CH_PER_SCALE[1]) \n",
    "        self.down2 = down(CH_PER_SCALE[1],CH_PER_SCALE[2])\n",
    "        self.down3 = down(CH_PER_SCALE[2],CH_PER_SCALE[3])                \n",
    "        self.down4 = down(CH_PER_SCALE[3],CH_PER_SCALE[4])                \n",
    "        self.up1 = up(CH_PER_SCALE[4]+CH_PER_SCALE[3],CH_PER_SCALE[3])\n",
    "        self.up2 = up(CH_PER_SCALE[3]+CH_PER_SCALE[2],CH_PER_SCALE[2])\n",
    "        self.up3 = up(CH_PER_SCALE[2]+CH_PER_SCALE[1],CH_PER_SCALE[1])\n",
    "        self.up4 = up(CH_PER_SCALE[1]+CH_PER_SCALE[0],CH_PER_SCALE[0])\n",
    "        self.outc = nn.Conv2d(CH_PER_SCALE[0], out_ch, 1, padding = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.inc(x)\n",
    "        x0 = self.inc2(x0)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x3_up = self.up1(x4,x3)\n",
    "        x2_up = self.up2(x3_up,x2)\n",
    "        x1_up = self.up3(x2_up,x1)\n",
    "        out = self.up4(x1_up,x0)\n",
    "        out = self.outc(out)\n",
    "#         out = F.pixel_shuffle(out,2) ## Paper final step rearranges 12 channes to 3 RGB channels\n",
    "#         out = F.hardtanh(out, min_val=0, max_val=1) #Clamp the top and bottom to 0,1 since pixels can only be in this value\n",
    "        return out\n",
    "    \n",
    "class PRIDNet(nn.Module):\n",
    "    def __init__(self, in_ch = 4, out_ch = 12):\n",
    "        super(PRIDNet, self).__init__()\n",
    "        self.feature_extraction = nn.Sequential(conv_lrelu(in_ch, 32), *[conv_lrelu(32, 32) for i in range(3)])\n",
    "        self.unet0 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet1 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet2 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet3 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet4 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.avgpool1 = nn.AvgPool2d((2,2))\n",
    "        self.avgpool2 = nn.AvgPool2d((4,4))\n",
    "        self.avgpool3 = nn.AvgPool2d((8,8))\n",
    "        self.avgpool4 = nn.AvgPool2d((16,16))\n",
    "        self.up4 =  nn.UpsamplingBilinear2d(scale_factor = 16)\n",
    "        self.up3 =  nn.UpsamplingBilinear2d(scale_factor = 8)\n",
    "        self.up2 =  nn.UpsamplingBilinear2d(scale_factor = 4)\n",
    "        self.up1 =  nn.UpsamplingBilinear2d(scale_factor = 2)\n",
    "        self.out =  nn.Conv2d(32+12*5, out_ch, 1, padding = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_feat = self.feature_extraction(x)\n",
    "        x0 = self.unet0(x_feat)\n",
    "        x1 = self.up1(self.unet1(self.avgpool1(x_feat)))\n",
    "        x2 = self.up2(self.unet2(self.avgpool2(x_feat)))\n",
    "        x3 = self.up3(self.unet3(self.avgpool3(x_feat)))\n",
    "        x4 = self.up4(self.unet4(self.avgpool4(x_feat)))\n",
    "        if x1.shape != x0.shape:\n",
    "            x1 = transforms.functional.resize(x1, x0.shape[2:])\n",
    "        if x2.shape != x0.shape:\n",
    "            x2 = transforms.functional.resize(x2, x0.shape[2:])\n",
    "        if x3.shape != x0.shape:\n",
    "            x3 = transforms.functional.resize(x3, x0.shape[2:])\n",
    "        if x4.shape != x0.shape:\n",
    "            x4 = transforms.functional.resize(x4, x0.shape[2:])\n",
    "        x_unet_all = torch.cat([x_feat,x0,x1,x2,x3,x4], axis = 1)\n",
    "        out = self.out(x_unet_all)\n",
    "        \n",
    "        out = F.pixel_shuffle(out,2) ## Paper final step rearranges 12 channes to 3 RGB channels\n",
    "        out = F.hardtanh(out, min_val=0, max_val=1) #Clamp the top and bottom to 0,1 since pixels can only be in this value\n",
    "        return out\n",
    "    \n",
    "    def load_my_state_dict(self, state_dict):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                 continue\n",
    "            #if isinstance(param, self.Parameter):\n",
    "            else:\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = UNet(in_ch = 4, CH_PER_SCALE = [32,64,128,256,512], out_ch = 12)\n",
    "# model = model.cuda()\n",
    "# # model.load_state_dict(torch.load('./results_Sony/sony3830.pth'))\n",
    "# model.load_state_dict(torch.load('./results_UNet/net_weights/sony3996.pth'))\n",
    "\n",
    "model = PRIDNet()\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load('./results_Sony/sony3830.pth'))\n",
    "# model.load_state_dict(torch.load('./results_SSIM/net_weights/sony2601.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "with open('./Dataset/Sony_val_raw_list.pickle','rb') as f:\n",
    "    val_raw_list = pickle.load(f)\n",
    "val_raw_list = ['./Dataset/'+path for path in val_raw_list]\n",
    "with open('./Dataset/Sony_val_gt_list.pickle','rb') as f:\n",
    "    val_gt_list = pickle.load(f)\n",
    "val_gt_list = ['./Dataset/'+path for path in val_gt_list]\n",
    "\n",
    "Val_PSNR, Val_SSIM, Val_MSSSIM = validate(model, val_raw_list, val_gt_list,block_size = None, batch_size = 1, \n",
    "                                          save_img_dir = './Output_Images_PRIDNet_MSE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.202051\n",
      "0.7219911\n",
      "0.8361999\n"
     ]
    }
   ],
   "source": [
    "print(Val_PSNR)\n",
    "print(Val_SSIM)\n",
    "print(Val_MSSSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_env2]",
   "language": "python",
   "name": "conda-env-torch_env2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
