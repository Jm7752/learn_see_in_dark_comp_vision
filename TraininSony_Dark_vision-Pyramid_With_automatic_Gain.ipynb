{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:         128830       10871       98477        2665       19480      112514\r\n",
      "Swap:         97162        2477       94685\r\n"
     ]
    }
   ],
   "source": [
    "! free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, time\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import rawpy\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "%matplotlib inline\n",
    "\n",
    "input_dir = './dataset/Sony/short/'\n",
    "gt_dir = './dataset/Sony/long/'\n",
    "checkpoint_dir = './result_Sony/'\n",
    "result_dir = './result_Sony/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    deviceTag = torch.device('cuda')\n",
    "else:\n",
    "    deviceTag = torch.device('cpu')\n",
    "print(deviceTag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train IDs\n",
    "train_fns = glob.glob(gt_dir + '0*.ARW')\n",
    "train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]\n",
    "\n",
    "ps = 512  # patch size for training\n",
    "save_freq = 500\n",
    "\n",
    "DEBUG = 0\n",
    "if DEBUG == 1:\n",
    "    save_freq = 2\n",
    "    train_ids = train_ids[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "print(len(train_fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class conv_lrelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_lrelu, self).__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_ch,out_ch,3, padding = 1),nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.conv1 = conv_lrelu(in_ch,out_ch)\n",
    "        self.conv2 = conv_lrelu(out_ch,out_ch)\n",
    "        self.down =  nn.MaxPool2d((2,2))\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.down(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up, self).__init__()       \n",
    "        self.up =  nn.UpsamplingBilinear2d(scale_factor = 2)\n",
    "        self.conv1 = conv_lrelu(in_ch,out_ch) \n",
    "        self.conv2 = conv_lrelu(out_ch,out_ch) \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        if x1.shape != x2.shape:\n",
    "            x1 = transforms.functional.resize(x1, x2.shape[2:])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class luminanceGain(nn.Module):\n",
    "    def __init__(self, in_ch = 4, CH_PER_SCALE = [32,64,64,64,64]):\n",
    "        super(luminanceGain, self).__init__()\n",
    "        self.inc = conv_lrelu(in_ch, CH_PER_SCALE[0])\n",
    "        self.inc2 = conv_lrelu(CH_PER_SCALE[0], CH_PER_SCALE[0])\n",
    "        self.down1 = down(CH_PER_SCALE[0], CH_PER_SCALE[1]) \n",
    "        self.down2 = down(CH_PER_SCALE[1],CH_PER_SCALE[2])\n",
    "        self.down3 = down(CH_PER_SCALE[2],CH_PER_SCALE[3])                \n",
    "        self.down4 = down(CH_PER_SCALE[3],CH_PER_SCALE[4]) \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(64,1)\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.inc2(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.down4(x)\n",
    "        x = self.pool(x) # This adaptive pool all the 4x4x512 channels to 1x1x512.\n",
    "        #THis greatly speeds up the training speed of our network\n",
    "        x = x.view(-1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = F.sigmoid(x)*500+30\n",
    "        return out\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch = 4, CH_PER_SCALE = [32,64,128,256,512], out_ch = 12):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = conv_lrelu(in_ch, CH_PER_SCALE[0])\n",
    "        self.inc2 = conv_lrelu(CH_PER_SCALE[0], CH_PER_SCALE[0])\n",
    "        self.down1 = down(CH_PER_SCALE[0], CH_PER_SCALE[1]) \n",
    "        self.down2 = down(CH_PER_SCALE[1],CH_PER_SCALE[2])\n",
    "        self.down3 = down(CH_PER_SCALE[2],CH_PER_SCALE[3])                \n",
    "        self.down4 = down(CH_PER_SCALE[3],CH_PER_SCALE[4])                \n",
    "        self.up1 = up(CH_PER_SCALE[4]+CH_PER_SCALE[3],CH_PER_SCALE[3])\n",
    "        self.up2 = up(CH_PER_SCALE[3]+CH_PER_SCALE[2],CH_PER_SCALE[2])\n",
    "        self.up3 = up(CH_PER_SCALE[2]+CH_PER_SCALE[1],CH_PER_SCALE[1])\n",
    "        self.up4 = up(CH_PER_SCALE[1]+CH_PER_SCALE[0],CH_PER_SCALE[0])\n",
    "        self.outc = nn.Conv2d(CH_PER_SCALE[0], out_ch, 1, padding = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.inc(x)\n",
    "        x0 = self.inc2(x0)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x3_up = self.up1(x4,x3)\n",
    "        x2_up = self.up2(x3_up,x2)\n",
    "        x1_up = self.up3(x2_up,x1)\n",
    "        out = self.up4(x1_up,x0)\n",
    "        out = self.outc(out)\n",
    "#         out = F.pixel_shuffle(out,2) ## Paper final step rearranges 12 channes to 3 RGB channels\n",
    "#         out = F.hardtanh(out, min_val=0, max_val=1) #Clamp the top and bottom to 0,1 since pixels can only be in this value\n",
    "        return out\n",
    "    \n",
    "class PRIDNet(nn.Module):\n",
    "    def __init__(self, in_ch = 4, out_ch = 12):\n",
    "        super(PRIDNet, self).__init__()\n",
    "        self.gain = luminanceGain()\n",
    "        self.feature_extraction = nn.Sequential(conv_lrelu(in_ch, 32), *[conv_lrelu(32, 32) for i in range(3)])\n",
    "        self.unet0 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet1 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet2 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet3 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.unet4 = UNet(in_ch = 32, out_ch = 12)\n",
    "        self.avgpool1 = nn.AvgPool2d((2,2))\n",
    "        self.avgpool2 = nn.AvgPool2d((4,4))\n",
    "        self.avgpool3 = nn.AvgPool2d((8,8))\n",
    "        self.avgpool4 = nn.AvgPool2d((16,16))\n",
    "        self.up4 =  nn.UpsamplingBilinear2d(scale_factor = 16)\n",
    "        self.up3 =  nn.UpsamplingBilinear2d(scale_factor = 8)\n",
    "        self.up2 =  nn.UpsamplingBilinear2d(scale_factor = 4)\n",
    "        self.up1 =  nn.UpsamplingBilinear2d(scale_factor = 2)\n",
    "        self.out =  nn.Conv2d(32+12*5, out_ch, 1, padding = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        amp_factor = self.gain(x)\n",
    "       # print(x.shape)\n",
    "        #print(amp_factor.shape)\n",
    "        x = amp_factor[0,0]*x\n",
    "        #x[1] = amp_factor[1,0]*x[1];\n",
    "        #x[2] = amp_factor[2,0]*x[2];\n",
    "        #x[3] = amp_factor[3,0]*x[3];\n",
    "        #x[4] = amp_factor[4,0]*x[4];\n",
    "        #x[5] = amp_factor[5,0]*x[5];\n",
    "        #x[6] = amp_factor[6,0]*x[6];\n",
    "        #x[7] = amp_factor[7,0]*x[7];\n",
    "\n",
    "        x_feat = self.feature_extraction(x)\n",
    "        x0 = self.unet0(x_feat)\n",
    "        x1 = self.up1(self.unet1(self.avgpool1(x_feat)))\n",
    "        x2 = self.up2(self.unet2(self.avgpool2(x_feat)))\n",
    "        x3 = self.up3(self.unet3(self.avgpool3(x_feat)))\n",
    "        x4 = self.up4(self.unet4(self.avgpool4(x_feat)))\n",
    "        x_unet_all = torch.cat([x_feat,x0,x1,x2,x3,x4], axis = 1)\n",
    "        out = self.out(x_unet_all)\n",
    "        \n",
    "        out = F.pixel_shuffle(out,2) ## Paper final step rearranges 12 channes to 3 RGB channels\n",
    "        out = F.hardtanh(out, min_val=0, max_val=1) #Clamp the top and bottom to 0,1 since pixels can only be in this value\n",
    "        return out\n",
    "    \n",
    "    def load_my_state_dict(self, state_dict):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                 continue\n",
    "            #if isinstance(param, self.Parameter):\n",
    "            else:\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for packing raw and saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data takes long time to load. Keep them in memory after loaded.\n",
    "gt_images = [None] * 6000\n",
    "input_images = {}\n",
    "input_images['300'] = [None] * len(train_ids)\n",
    "input_images['250'] = [None] * len(train_ids)\n",
    "input_images['100'] = [None] * len(train_ids)\n",
    "\n",
    "g_loss = np.zeros((5000, 1))\n",
    "\n",
    "allfolders = glob.glob(result_dir + '*0')\n",
    "\n",
    "for folder in allfolders:\n",
    "    lastepoch = np.maximum(epochs, int(folder[-4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out\n",
    "\n",
    "def process_img(input_raw_img, model):\n",
    "    ## Process image(s) using the given model\n",
    "    # input_raw_img: numpy array, dimension: (Batch,Height,Width,Channel)\n",
    "    # ratio: numpy array, dimension: (Batch,)\n",
    "    model.eval();\n",
    "    model.to(deviceTag)\n",
    "    #ratio = ratio.reshape(ratio.shape[0],1,1,1)\n",
    "    input_raw_img = np.transpose(input_raw_img, [0,3,1,2]).astype('float32')#*ratio\n",
    "    input_tensor = torch.from_numpy(input_raw_img.copy()).float().to(deviceTag)\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)\n",
    "    output_img = output_tensor.cpu().numpy()\n",
    "    output_img = np.transpose(output_img, [0,2,3,1])\n",
    "    \n",
    "    return output_img\n",
    "\n",
    "def ssim_numpy(img1, img2):\n",
    "    img1, img2 = torch.tensor(np.transpose(img1,(2,0,1))).unsqueeze(0), torch.tensor(np.transpose(img2,(2,0,1))).unsqueeze(0)\n",
    "    ssim_calc = ssim(img1,img2, data_range=1, size_average=True)\n",
    "    msssim_calc = ms_ssim(img1,img2, data_range=1, size_average=True)\n",
    "    return ssim_calc.numpy(), msssim_calc.numpy()\n",
    "    \n",
    "def validate(model, input_list, gt_list, block_size = None, batch_size = 8, save_img_dir = None):\n",
    "    assert len(input_list) == len(gt_list)\n",
    "    \n",
    "    model.eval();\n",
    "    PSNR_list = []\n",
    "    SSIM_list = []\n",
    "    MSSSIM_list = []\n",
    "    \n",
    "    for i in range(len(input_list)//batch_size):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        input_raw_img_batch = []\n",
    "        gt_img_batch = []\n",
    "        ratio_batch = []\n",
    "        for b in range(batch_size):\n",
    "            if i*batch_size+b < len(input_list):\n",
    "                in_path = input_list[i*batch_size+b]\n",
    "                gt_path = gt_list[i*batch_size+b]\n",
    "            else:\n",
    "                break\n",
    "            in_fn = os.path.basename(in_path)\n",
    "            gt_fn = os.path.basename(gt_path)\n",
    "            in_exposure = float(in_fn[9:-5])\n",
    "            gt_exposure = float(gt_fn[9:-5])\n",
    "            #ratio = min(gt_exposure / in_exposure, 300)\n",
    "        \n",
    "            raw = rawpy.imread(in_path)\n",
    "            input_raw_img = pack_raw(raw)\n",
    "            \n",
    "            gt_raw = rawpy.imread(gt_path)\n",
    "            gt_img = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            gt_img = np.float32(gt_img / 65535.0)\n",
    "            \n",
    "            if block_size is not None:\n",
    "                i_cut, j_cut = np.random.randint(0,input_raw_img.shape[0]-block_size), np.random.randint(0,input_raw_img.shape[1]-block_size)\n",
    "                gt_img = gt_img[i_cut*2:i_cut*2+block_size*2, j_cut*2:j_cut*2+block_size*2, :]\n",
    "                input_raw_img = input_raw_img[i_cut:i_cut+block_size, j_cut:j_cut+block_size, :]\n",
    "            \n",
    "            #ratio_batch.append(ratio)\n",
    "            input_raw_img_batch.append(input_raw_img)\n",
    "            gt_img_batch.append(gt_img)\n",
    "        \n",
    "        input_raw_img_batch = np.array(input_raw_img_batch)\n",
    "        #ratio_batch = np.array(ratio_batch)\n",
    "        gt_img_batch = np.array(gt_img_batch)\n",
    "        \n",
    "        output_img_batch = process_img(input_raw_img_batch, model)\n",
    "        if save_img_dir is not None and i < 20:\n",
    "            plt.imsave(save_img_dir+'{}_gt.png'.format(i),gt_img_batch[0,:,:,:])\n",
    "            plt.imsave(save_img_dir+'{}_out.png'.format(i),output_img_batch[0,:,:,:])\n",
    "        MSE = np.mean((output_img_batch.reshape(output_img_batch.shape[0],-1) - gt_img_batch.reshape(gt_img_batch.shape[0],-1))**2, axis = 1)\n",
    "        PSNR_batch = 10*np.log10(1/MSE)\n",
    "        PSNR_list.append(list(PSNR_batch))\n",
    "        ssim_calc, msssim_calc = ssim_numpy(gt_img_batch[0,:,:,:], output_img_batch[0,:,:,:])\n",
    "        SSIM_list.append(ssim_calc)\n",
    "        MSSSIM_list.append(msssim_calc)\n",
    "    \n",
    "    Val_PSNR = np.mean(PSNR_list)\n",
    "    Val_SSIM = np.mean(SSIM_list)\n",
    "    Val_MSSSIM = np.mean(MSSSIM_list)\n",
    "    return Val_PSNR, Val_SSIM, Val_MSSSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH_A = './results_Sony/Imp_Models/Pyramid_network.pth'\n",
    "PATH_B = './results_Sony/sony{}.pth'.format(999)\n",
    "model_Avg = torch.load(PATH_B,deviceTag)\n",
    "#n_models = 10\n",
    "#\n",
    "#for i in range(n_models-1):\n",
    "#    PATH_B = './results_Sony/sony{}.pth'.format(3829-i)\n",
    "#    model_load = torch.load(PATH_B,deviceTag)\n",
    "#    for key in model_Avg:\n",
    "#        model_Avg[key] = model_Avg[key] + model_load[key]\n",
    "#for key in model_Avg:\n",
    "#    model_Avg[key] = model_Avg[key]/n_models\n",
    "# model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39594393\n"
     ]
    }
   ],
   "source": [
    "model = PRIDNet().to(deviceTag)\n",
    "model.load_my_state_dict(model_Avg) ## Model Amplification \n",
    "#Print the number of parameters good for characterizing the size\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-4fb34fd350f0>:28: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
      "/scratch/jm7752/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "<ipython-input-15-4fb34fd350f0>:28: DeprecationWarning: This function is deprecated. Please call randint(0, 0 + 1) instead\n",
      "  in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
      "<ipython-input-15-4fb34fd350f0>:28: DeprecationWarning: This function is deprecated. Please call randint(0, 2 + 1) instead\n",
      "  in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished ! Loss: 0.0023224143762761865\n",
      "Checkpoint 1 saved !\n"
     ]
    }
   ],
   "source": [
    "Start_epoch = 0\n",
    "epochs = 1\n",
    "learning_rate = 1e-5\n",
    "model_save_path = './results_Sony/'  # directory to same the model after each epoch. \n",
    "batch_num = 1;\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# note that although we want to use DICE for evaluation, we use BCELoss for training in this example\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1) #Step Scheduler. \n",
    "TrainingLossData = np.zeros(epochs)\n",
    "# The loss function we use is binary cross entropy: nn.BCELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "# note that although we want to use DICE for evaluation, we use BCELoss for training in this example\n",
    "trainF= open(\"./epoch_loss/TrainingEpoch.txt\",\"w+\")\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(Start_epoch, Start_epoch+epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    epoch_loss = 0 ## Set Epoch Loss\n",
    "    count = 0;\n",
    "    batches_processed = 0\n",
    "    ##This version has a batch size of 1. In the future conside increasing batchsize\n",
    "    for ind in np.random.permutation(len(train_ids)):    \n",
    "        # get the path from image id\n",
    "        train_id = train_ids[ind]\n",
    "        in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id)\n",
    "        in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
    "        in_fn = os.path.basename(in_path)\n",
    "\n",
    "        gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id)\n",
    "        gt_path = gt_files[0]\n",
    "        gt_fn = os.path.basename(gt_path)\n",
    "        in_exposure = float(in_fn[9:-5])\n",
    "        gt_exposure = float(gt_fn[9:-5])\n",
    "        ratio = min(gt_exposure / in_exposure, 300)\n",
    "\n",
    "        st = time.time()\n",
    "\n",
    "        if input_images[str(ratio)[0:3]][ind] is None:\n",
    "            raw = rawpy.imread(in_path)\n",
    "            input_images[str(ratio)[0:3]][ind] = np.expand_dims(pack_raw(raw), axis=0)# * ratio\n",
    "#\n",
    "            gt_raw = rawpy.imread(gt_path)\n",
    "            im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            gt_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "\n",
    "        # crop\n",
    "        H = input_images[str(ratio)[0:3]][ind].shape[1]\n",
    "        W = input_images[str(ratio)[0:3]][ind].shape[2]\n",
    "\n",
    "        xx = np.random.randint(0, W - ps)\n",
    "        yy = np.random.randint(0, H - ps)\n",
    "        input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps, xx:xx + ps, :]\n",
    "        gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]\n",
    "\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
    "            input_patch = np.flip(input_patch, axis=1)\n",
    "            gt_patch = np.flip(gt_patch, axis=1)\n",
    "        if np.random.randint(2, size=1)[0] == 1:\n",
    "            input_patch = np.flip(input_patch, axis=2)\n",
    "            gt_patch = np.flip(gt_patch, axis=2)\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
    "            input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
    "            gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\n",
    "        #(1, 512, 512, 4)\n",
    "        #(1, 1024, 1024, 3)\n",
    "        input_patch = np.transpose(input_patch, (0,3,1,2))\n",
    "        input_patch = torch.from_numpy(input_patch.copy()).cuda()\n",
    "        gt_patch = np.transpose(gt_patch, (0,3,1,2))\n",
    "        gt_patch = torch.from_numpy(gt_patch.copy()).cuda()\n",
    "        ##Batch concatenation\n",
    "        if count%(batch_num)==0:\n",
    "            input_patch_all = input_patch\n",
    "            gt_patch_all = gt_patch\n",
    "        else:\n",
    "            input_patch_all = torch.cat([input_patch_all, input_patch], dim=0)\n",
    "            gt_patch_all = torch.cat([gt_patch_all, gt_patch], dim=0)\n",
    "        ##Every N batches we ship it back \n",
    "        if count%(batch_num)==batch_num-1:\n",
    "            #print(input_patch_all.shape)\n",
    "            img_pred = model.forward(input_patch_all)\n",
    "            loss = criterion(img_pred, gt_patch_all)\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batches_processed += 1\n",
    "            ##print(epoch_loss/count);\n",
    "        count = count +1\n",
    "    scheduler.step()\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / batches_processed))\n",
    "    trainF.write('Epoch finished ! Loss: {}\\r\\n'.format(epoch_loss / batches_processed))\n",
    "    TrainingLossData[epoch] = epoch_loss / batches_processed ## Save for plotting\n",
    "    ################################################ [TODO] ###################################################\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    # Save the model after every 10 epochs. This save our Memory on HPC.\n",
    "    ##Save Top results after 95%\n",
    "    if epoch > epochs*0.95:\n",
    "        if os.path.isdir(model_save_path):\n",
    "            torch.save(model.state_dict(),model_save_path + 'sony{}.pth'.format(epoch + 1))\n",
    "        else:\n",
    "            os.makedirs(model_save_path, exist_ok=True)\n",
    "            torch.save(model.state_dict(),model_save_path + 'sony{}.pth'.format(epoch + 1))\n",
    "        print('Checkpoint {} saved !'.format(epoch + 1))\n",
    "    if epoch%99 == 0:\n",
    "        if os.path.isdir(model_save_path):\n",
    "            torch.save(model.state_dict(),model_save_path + 'sony{}.pth'.format(epoch + 1))\n",
    "        else:\n",
    "            os.makedirs(model_save_path, exist_ok=True)\n",
    "            torch.save(model.state_dict(),model_save_path + 'sony{}.pth'.format(epoch + 1))\n",
    "        print('Checkpoint {} saved !'.format(epoch + 1))\n",
    "\n",
    "trainF.close() ## Close your files to write to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(model_save_path):\n",
    "            torch.save(model.state_dict(),model_save_path + 'sony{}.pth'.format(epoch + 1))\n",
    "else:\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(),model_save_path + 'sony{}.pth'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to display 10 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/jm7752/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "with open('./dataset/Sony_val_raw_list.pickle','rb') as f:\n",
    "    val_raw_list = pickle.load(f)\n",
    "val_raw_list = ['./dataset/'+path for path in val_raw_list]\n",
    "with open('./dataset/Sony_val_gt_list.pickle','rb') as f:\n",
    "    val_gt_list = pickle.load(f)\n",
    "val_gt_list = ['./dataset/'+path for path in val_gt_list]\n",
    "\n",
    "## Leave save_img_dir as None, if you don't want to save the result images\n",
    "Val_PSNR, Val_SSIM, Val_MSSSIM = validate(model, val_raw_list, val_gt_list,block_size = None, batch_size = 1, \n",
    "                                          save_img_dir = './images_AutoLG/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.030909\n",
      "0.6923857\n",
      "0.8146631\n"
     ]
    }
   ],
   "source": [
    "print(Val_PSNR)\n",
    "print(Val_SSIM)\n",
    "print(Val_MSSSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
